#install.packages("bbl") #package used to convert to raw data
library(bbl) #call the package
x <- as.data.frame(Titanic) #put as a data frame
head(x)
dim(x)
titanic = freq2raw(data=x[,1:4], freq=x$Freq) #convert to the raw data
head(titanic)
dim(titanic)
#Creating Test/Training data sets
set.seed(101) #set seed
#Select 75% of the data
sample = sample.int(n = nrow(titanic),size = round(.75*nrow(titanic)),
replace = FALSE)
head(sample)
train = titanic[sample,]
train = titanic[sample,]
#Select 75% of the data
sample = sample.int(n = nrow(titanic),size = round(.75*nrow(titanic)),
replace = FALSE)
head(sample)
train = titanic[sample,]
test = titanic[-sample,]
dim(train)
dim(test)
summary(titanic)
#Create the model
titanic.glm = glm(Survived ~ Sex, family = "binomial",
data = train)
summary(titanic.glm)
boxplot(Freq ~ Survived + Sex, data = x)
#Creating a Confusion Matrix
predict.titanic.train = predict(titanic.glm,type = "response")
head(cbind(train,predict.titanic.train))
#Cleaning the BreastCancer data
#install.packages("mlbench")
data(BreastCancer,package = "mlbench")
summary(BreastCancer)
#Create a copy with no missing values and remove id column
bc <- BreastCancer[complete.cases(BreastCancer), ]
bc <- bc[,-1] # remove id column
#Convert the factors to numeric
for(i in 1:9) {
bc[, i] <- as.numeric(as.character(bc[, i]))
}
summary(bc)
class = ifelse(bc$Class == "malignant", 1, 0)
class = as.factor(class)
summary(class)
#To get the logistic model
fit.bc = glm(Class ~ Cell.shape, family = "binomial", data = bc)
summary(fit.bc)
#Getting the predictor
predict.glm(fit.bc,newdata = data.frame(Cell.shape = 5))
predict.glm(fit.bc,newdata = data.frame(Cell.shape = 5),
type = "response")
#Lab Questions
fit2.bc = glm(Class ~ Cl.thickness,family = "binomial", data = bc)
summary(fit2.bc)
predict.glm(fit2.bc,newdata = data.frame(Cl.thickness = 5),type = "response")
#Setting the frequency table to raw data
Titanic
#install.packages("bbl") #package used to convert to raw data
library(bbl) #call the package
x <- as.data.frame(Titanic) #put as a data frame
head(x)
dim(x)
titanic = freq2raw(data=x[,1:4], freq=x$Freq) #convert to the raw data
head(titanic)
dim(titanic)
#Creating Test/Training data sets
set.seed(101) #set seed
#Select 75% of the data
sample = sample.int(n = nrow(titanic),size = round(.75*nrow(titanic)),
replace = FALSE)
head(sample)
train = titanic[sample,]
test = titanic[-sample,]
dim(train)
dim(test)
summary(titanic)
#Create the model
titanic.glm = glm(Survived ~ Sex, family = "binomial",
data = train)
summary(titanic.glm)
boxplot(Freq ~ Survived + Sex, data = x)
#Creating a Confusion Matrix
predict.titanic.train = predict(titanic.glm,type = "response")
head(cbind(train,predict.titanic.train))
table(titanic$Sex,titanic$Survived)
367/(1364+367)
344/(126+344)
predict.survive.train = ifelse(predict.titanic.train < 0.5, "No","Yes")
(conf.mat.train = table(predict.survive.train,train$Survived))
(conf.mat.train[1,2]+conf.mat.train[2,1])/sum(conf.mat.train)
#Confusion Matrix on Test Data
predict.titanic = predict(titanic.glm,type = "response", newdata = test)
head(predict.titanic)
predict.survive = ifelse(predict.titanic< 0.5,"No","Yes")
(conf.mat = table(predict.survive,test$Survived))
#Testing Error Rate
(conf.mat[1,2]+conf.mat[2,1])/sum(conf.mat)
#sensitivity
conf.mat[2,2]/(conf.mat[1,2]+conf.mat[2,2])
#Specificity
conf.mat[1,1]/(conf.mat[1,1]+conf.mat[2,1])
pred= ifelse(predict(mylogis, test.data, type = "response")<0.5, 0,1)
pred= ifelse(predict(mylogis, test.data, type = "response")<0.5, 0,1)
pred
data[-sample,1]
test.data =  data[-sample, ]
mylogis= glm(formula = conterfeit~ Length+ Left+ Right+ Bottom+ Top +Diagonal, data= train.data, family = binomial)
summary(mylogis)
test.data
test.data[,1]
test.data[,-1]
pred= ifelse(predict(mylogis, test.data[,-1], type = "response")<0.5, 0,1)
pred
data= read.csv("banknotes.csv")
fake= data[data$conterfeit==0,-1]
real= data[data$conterfeit==1,-1]
### MANOVA
### check for condition:
library(MVN)
mvn(data)
mvn(fake)
mvn(real)
### not multivariate normal
### check for equal variance
library(biotools)
boxM(data[,-1], data$conterfeit)
### not equal variance
#### hence not meet the criteria for MANOVA
#### apply MANOVA even if the criteria is not met.
attach(data)
summary(manova(cbind(Length, Left, Right, Bottom, Top, Diagonal)~conterfeit), test = "Wilks")
### there is a different in the mean of the type of money.
### However, Manova is not a good test for the data due to insufficent criteria is met.
### Logistic
library(ppsr)
set.seed(1)
score(data, data$Left,  data$conterfeit, algorithm = "logistic_reg")
sample = sample.int(n = nrow(data),size = round(.75*nrow(data)),
replace = FALSE)
train.data=  data[sample, ]
test.data =  data[-sample, ]
mylogis= glm(formula = conterfeit~ Length+ Left+ Right+ Bottom+ Top +Diagonal, data= train.data, family = binomial)
summary(mylogis)
pred= ifelse(predict(mylogis, test.data[,-1], type = "response")<0.5, 0,1)
test.data[,1]
sum(pred== test.data[,1])/ 50
## accuracy
sum(pred== test.data[,1])/50
train.pred= ifelse(predict(mylogis, train.data[,-1], type = "response")<0.5, 0,1)
sum(train.pred== train.data[,1])/150
## training accuracy
train.pred= ifelse(predict(mylogis, train.data[,-1], type = "response")<0.5, 0,1)
sum(train.pred== train.data[,1])/150
## testing accuracy
sum(pred== test.data[,1])/50
table(pred, test.data[,1])
pnorm(70, 65,4.0311)-pnorm(82,65, 4.0311)
-pnorm(70, 65,4.0311)+pnorm(82,65, 4.0311)
pnorm
sqrt(130*.5*.5)
sqrt(130*.5*.5)
-pnorm(70, 65,5.700877)+pnorm(82,65, 5.700877)
-pnorm(70, mean= 65, sd=5.700877)+pnorm(82,65, 5.700877)
1-pnorm(11,14,3.4157)
1-pnorm(11,1/6*84,sqrt(84*1/6*5/6))
table(pred, test.data[,1])
table(pred, test.data[,1])
a
---
title: "Statstical analysis Group 5"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# PCA analysis
# Manova analysis and Multivariate logistic regression
data= read.csv("banknotes.csv")
fake= data[data$conterfeit==0,-1]
real= data[data$conterfeit==1,-1]
### MANOVA
### check for condition:
library(MVN)
mvn(data)
mvn(fake)
mvn(real)
### not multivariate normal
### check for equal variance
library(biotools)
boxM(data[,-1], data$conterfeit)
### not equal variance
#### hence not meet the criteria for MANOVA
#### apply MANOVA even if the criteria is not met.
attach(data)
summary(manova(cbind(Length, Left, Right, Bottom, Top, Diagonal)~conterfeit), test = "Wilks")
### there is a different in the mean of the type of money.
### However, Manova is not a good test for the data due to insufficent criteria is met.
### Logistic
library(ppsr)
set.seed(1)
score(data, data$Left,  data$conterfeit, algorithm = "logistic_reg")
sample = sample.int(n = nrow(data),size = round(.75*nrow(data)),
replace = FALSE)
train.data=  data[sample, ]
test.data =  data[-sample, ]
mylogis= glm(formula = conterfeit~ Length+ Left+ Right+ Bottom+ Top +Diagonal, data= train.data, family = binomial)
summary(mylogis)
## training accuracy
train.pred= ifelse(predict(mylogis, train.data[,-1], type = "response")<0.5, 0,1)
sum(train.pred== train.data[,1])/150
## testing accuracy
pred= ifelse(predict(mylogis, test.data[,-1], type = "response")<0.5, 0,1)
sum(pred== test.data[,1])/50
## confusion matrix for testing accuracy
table(pred, test.data[,1])
---
title: "Statstical analysis Group 5"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# PCA analysis
# Manova analysis and Multivariate logistic regression
```{r}
data= read.csv("banknotes.csv")
fake= data[data$conterfeit==0,-1]
real= data[data$conterfeit==1,-1]
### MANOVA
### check for condition:
library(MVN)
mvn(data)
mvn(fake)
mvn(real)
### not multivariate normal
### check for equal variance
library(biotools)
boxM(data[,-1], data$conterfeit)
### not equal variance
#### hence not meet the criteria for MANOVA
#### apply MANOVA even if the criteria is not met.
attach(data)
summary(manova(cbind(Length, Left, Right, Bottom, Top, Diagonal)~conterfeit), test = "Wilks")
### there is a different in the mean of the type of money.
### However, Manova is not a good test for the data due to insufficent criteria is met.
### Logistic
library(ppsr)
set.seed(1)
score(data, data$Left,  data$conterfeit, algorithm = "logistic_reg")
sample = sample.int(n = nrow(data),size = round(.75*nrow(data)),
replace = FALSE)
train.data=  data[sample, ]
test.data =  data[-sample, ]
mylogis= glm(formula = conterfeit~ Length+ Left+ Right+ Bottom+ Top +Diagonal, data= train.data, family = binomial)
summary(mylogis)
## training accuracy
train.pred= ifelse(predict(mylogis, train.data[,-1], type = "response")<0.5, 0,1)
sum(train.pred== train.data[,1])/150
## testing accuracy
pred= ifelse(predict(mylogis, test.data[,-1], type = "response")<0.5, 0,1)
sum(pred== test.data[,1])/50
## confusion matrix for testing accuracy
table(pred, test.data[,1])
```
---
title: "Statstical analysis Group 5"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# PCA analysis
# Manova analysis and Multivariate logistic regression
```{r}
data= read.csv("banknotes.csv")
fake= data[data$conterfeit==0,-1]
real= data[data$conterfeit==1,-1]
### MANOVA
### check for condition:
library(MVN)
mvn(data)
mvn(fake)
mvn(real)
### not multivariate normal
### check for equal variance
library(biotools)
boxM(data[,-1], data$conterfeit)
### not equal variance
#### hence not meet the criteria for MANOVA
#### apply MANOVA even if the criteria is not met.
attach(data)
summary(manova(cbind(Length, Left, Right, Bottom, Top, Diagonal)~conterfeit), test = "Wilks")
### there is a different in the mean of the type of money.
### However, Manova is not a good test for the data due to insufficent criteria is met.
### Logistic
library(ppsr)
set.seed(1)
score(data, data$Left,  data$conterfeit, algorithm = "logistic_reg")
sample = sample.int(n = nrow(data),size = round(.75*nrow(data)),
replace = FALSE)
train.data=  data[sample, ]
test.data =  data[-sample, ]
mylogis= glm(formula = conterfeit~ Length+ Left+ Right+ Bottom+ Top +Diagonal, data= train.data, family = binomial)
summary(mylogis)
## training accuracy
train.pred= ifelse(predict(mylogis, train.data[,-1], type = "response")<0.5, 0,1)
sum(train.pred== train.data[,1])/150
## testing accuracy
pred= ifelse(predict(mylogis, test.data[,-1], type = "response")<0.5, 0,1)
sum(pred== test.data[,1])/50
## confusion matrix for testing accuracy
table(pred, test.data[,1])
```
---
title: "Statstical analysis Group 5"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# PCA analysis
# Manova analysis and Multivariate logistic regression
```{r}
data= read.csv("banknotes.csv")
fake= data[data$conterfeit==0,-1]
real= data[data$conterfeit==1,-1]
### MANOVA
### check for condition:
library(MVN)
mvn(data)
mvn(fake)
mvn(real)
### not multivariate normal
### check for equal variance
library(biotools)
boxM(data[,-1], data$conterfeit)
### not equal variance
#### hence not meet the criteria for MANOVA
#### apply MANOVA even if the criteria is not met.
attach(data)
summary(manova(cbind(Length, Left, Right, Bottom, Top, Diagonal)~conterfeit), test = "Wilks")
### there is a different in the mean of the type of money.
### However, Manova is not a good test for the data due to insufficent criteria is met.
### Logistic
library(ppsr)
set.seed(1)
score(data, data$Left,  data$conterfeit, algorithm = "logistic_reg")
sample = sample.int(n = nrow(data),size = round(.75*nrow(data)),
replace = FALSE)
train.data=  data[sample, ]
test.data =  data[-sample, ]
mylogis= glm(formula = conterfeit~ Length+ Left+ Right+ Bottom+ Top +Diagonal, data= train.data, family = binomial)
summary(mylogis)
## training accuracy
train.pred= ifelse(predict(mylogis, train.data[,-1], type = "response")<0.5, 0,1)
sum(train.pred== train.data[,1])/150
## testing accuracy
pred= ifelse(predict(mylogis, test.data[,-1], type = "response")<0.5, 0,1)
sum(pred== test.data[,1])/50
## confusion matrix for testing accuracy
table(pred, test.data[,1])
```
---
title: "Statstical analysis Group 5"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# PCA analysis
# Manova analysis and Multivariate logistic regression
```{r}
data= read.csv("banknotes.csv")
fake= data[data$conterfeit==0,-1]
real= data[data$conterfeit==1,-1]
### MANOVA
### check for condition:
library(MVN)
mvn(data)
mvn(fake)
mvn(real)
### not multivariate normal
### check for equal variance
library(biotools)
boxM(data[,-1], data$conterfeit)
### not equal variance
#### hence not meet the criteria for MANOVA
#### apply MANOVA even if the criteria is not met.
attach(data)
summary(manova(cbind(Length, Left, Right, Bottom, Top, Diagonal)~conterfeit), test = "Wilks")
### there is a different in the mean of the type of money.
### However, Manova is not a good test for the data due to insufficent criteria is met.
### Logistic
library(ppsr)
set.seed(1)
sample = sample.int(n = nrow(data),size = round(.75*nrow(data)),
replace = FALSE)
train.data=  data[sample, ]
test.data =  data[-sample, ]
mylogis= glm(formula = conterfeit~ Length+ Left+ Right+ Bottom+ Top +Diagonal, data= train.data, family = binomial)
summary(mylogis)
## training accuracy
train.pred= ifelse(predict(mylogis, train.data[,-1], type = "response")<0.5, 0,1)
sum(train.pred== train.data[,1])/150
## testing accuracy
pred= ifelse(predict(mylogis, test.data[,-1], type = "response")<0.5, 0,1)
sum(pred== test.data[,1])/50
## confusion matrix for testing accuracy
table(pred, test.data[,1])
```
knitr::opts_chunk$set(echo = TRUE)
banknotes=data
```{r}
data=colMeans(banknotes)
colMeans=matrix(data[2:7], nrow=6, ncol=1)
rownames(colMeans)=c("Length","Left","Right","Bottom","Top","Diagonal")
(colMeans)
data=colMeans(banknotes)
colMeans=matrix(data[2:7], nrow=6, ncol=1)
rownames(colMeans)=c("Length","Left","Right","Bottom","Top","Diagonal")
(colMeans)
```{r}
(cov.matrix=cov(banknotes[,-1]))
(cov.matrix=cov(banknotes[,-1]))
(total.variance=sum(diag(cov.matrix)))
(cov.matrix=cov(banknotes[,-1]))
(total.variance=sum(diag(cov.matrix)))
```{r}
hist(banknotes$Length)
---
title: "Swiss banknote PCA"
author: "Audrey Tedore and Zainab Mahmoud"
date: "`r Sys.Date()`"
output: pdf_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
**STEP 1:** Determining whether or not to scale the data
```{r}
banknotes=data
```
```{r}
data=colMeans(banknotes)
colMeans=matrix(data[2:7], nrow=6, ncol=1)
rownames(colMeans)=c("Length","Left","Right","Bottom","Top","Diagonal")
(colMeans)
```
```{r}
(cov.matrix=cov(banknotes[,-1]))
(total.variance=sum(diag(cov.matrix)))
```
```{r}
hist(banknotes$Length)
hist(banknotes$Left)
hist(banknotes$Right)
hist(banknotes$Bottom)
hist(banknotes$Top)
hist(banknotes$Diagonal)
```
**STEP 2:** Determining how many principal components
3 principal components can be used instead of the whole data matrix:
The first component PC1 can only account for 49.09% of the variation in bank notes, the first two components can account for 70.39%. The first three components can be used without major loss in accuracy since PC3's cumulative proportion is more than 80% at 84.88%. PC4 has a cumulative proportion of 92.374%, PC5 has a cumulative proportion of 96.852% and PC6 has 100% since all the predictors will be used.
```{r}
banknotesPCA=prcomp(banknotes[,-1],scale.=TRUE)
summary(banknotesPCA)
screeplot(banknotesPCA,type="lines")
```
**STEP 3:** Determining what variables are correlated to the principal components
Left, Right, Bottom,Top,and Diagonal are correlated to PC1.
Length is strongly correlated to PC2.
Bottom and Top are correlated to PC3.
```{r}
library(FactoMineR)
banknotesPCA2=PCA(banknotes[,-1],scale.unit=TRUE,graph=TRUE)
banknotesPCA2$var$cor
```
**STEP 4:** Regression using principal components
```{r}
set.seed(101)
sample = sample.int(n = nrow(banknotes),size = round(.80*nrow(banknotes)),
replace = FALSE)
train = banknotes[sample,]
test = banknotes[-sample,]
```
```{r}
pca<-banknotesPCA2$ind$coord[sample,1:3]
banknotes.glm = glm(conterfeit ~ pca, family = "binomial", data = train)
summary(banknotes.glm)
```
```{r}
banknotes.glm.probs=predict(banknotes.glm,type="response")
banknotes.glm.preds=ifelse(banknotes.glm.probs<0.5,"No","Yes")
(conf.mat=table(banknotes.glm.preds,train$conterfeit))
(train_error_rate=(conf.mat[1,2]+conf.mat[2,1])/sum(conf.mat))
```
```{r}
pca<-banknotesPCA2$ind$coord[-sample,1:3]
banknotes.glm.probs.1=predict(banknotes.glm,type="response",newdata=test)
banknotes.glm.preds.1=ifelse(banknotes.glm.probs.1<0.5,"No","Yes")
(conf.mat=table(banknotes.glm.preds.1,test$conterfeit))
(test_error_rate=(conf.mat[1,2]+conf.mat[2,1])/sum(conf.mat))
```
The test error rate is low and close to the train error rate, indicating that this is a good model.
```{r}
step(banknotes.glm)
```
All 3 principal components are needed in the model.
